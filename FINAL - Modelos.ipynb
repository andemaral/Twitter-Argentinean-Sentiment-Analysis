{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
    "from sklearn.metrics import recall_score, f1_score, roc_auc_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB,GaussianNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score,recall_score,f1_score,classification_report,auc,roc_curve,roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "seed=42\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('spanish')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize as TK\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# Para visualizar\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import FunctionTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = pd.read_csv('tweets_clean4.2 - para prediccion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    0.714557\n",
       "0.0    0.285443\n",
       "Name: sent, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw['sent'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>id</th>\n",
       "      <th>username</th>\n",
       "      <th>text_orig</th>\n",
       "      <th>text_modif</th>\n",
       "      <th>text_en</th>\n",
       "      <th>lenght</th>\n",
       "      <th>hashtags_orig</th>\n",
       "      <th>hashtags_modif</th>\n",
       "      <th>location</th>\n",
       "      <th>device</th>\n",
       "      <th>verified</th>\n",
       "      <th>rt</th>\n",
       "      <th>reply</th>\n",
       "      <th>sentiment_orig</th>\n",
       "      <th>sent</th>\n",
       "      <th>subj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-27 12:53:55+00:00</td>\n",
       "      <td>1162811195671416833</td>\n",
       "      <td>annyroshi_</td>\n",
       "      <td>#felizdomingo! hoy es un día especial y vale l...</td>\n",
       "      <td>hoy es un dia especial y vale la pena correrme...</td>\n",
       "      <td>Today is a special day and it is worth taking ...</td>\n",
       "      <td>252</td>\n",
       "      <td>['#felizdomingo!', '#eleccionesargentina']</td>\n",
       "      <td>felizdomingo!,eleccionesargentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>android</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sentiment(polarity=0.23435374149659863, subjec...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.255442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-27 12:53:56+00:00</td>\n",
       "      <td>404900481</td>\n",
       "      <td>gonza_v12</td>\n",
       "      <td>todas las boletas de macri rotas. escuela 57 d...</td>\n",
       "      <td>todas las boletas de macri rotas escuela 57 de...</td>\n",
       "      <td>all the macri school 57 broken tickets of el p...</td>\n",
       "      <td>111</td>\n",
       "      <td>['#eleccionesargentina']</td>\n",
       "      <td>eleccionesargentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iphone</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sentiment(polarity=-0.4, subjectivity=0.4)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-27 12:53:59+00:00</td>\n",
       "      <td>1165778412637736963</td>\n",
       "      <td>comunon</td>\n",
       "      <td>mas denuncias\\nmas escuelas clausuradas\\nmenos...</td>\n",
       "      <td>mas denuncias\\nmas escuelas clausuradas\\nmenos...</td>\n",
       "      <td>more complaints more schools closed less kirch...</td>\n",
       "      <td>277</td>\n",
       "      <td>['#seamoslibreslodemassearregla', '#sisepuede'...</td>\n",
       "      <td>seamoslibreslodemassearregla,sisepuede,maurici...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>android</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sentiment(polarity=0.18333333333333335, subjec...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-27 12:53:59+00:00</td>\n",
       "      <td>391643721</td>\n",
       "      <td>marchaorgar</td>\n",
       "      <td>#eleccionesargentina\\n\\nmientras nos preparamo...</td>\n",
       "      <td>mientras nos preparamos para el festejo nos an...</td>\n",
       "      <td>As we prepare for the celebration, we encourag...</td>\n",
       "      <td>211</td>\n",
       "      <td>['#eleccionesargentina', '#argentina']</td>\n",
       "      <td>eleccionesargentina,argentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>android</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sentiment(polarity=0.20625, subjectivity=0.7)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-27 12:54:03+00:00</td>\n",
       "      <td>1153794949336444928</td>\n",
       "      <td>xisdavidaii</td>\n",
       "      <td>que nuestros hermanos tengan sabiduría y hagan...</td>\n",
       "      <td>que nuestros hermanos tengan sabiduria y hagan...</td>\n",
       "      <td>that our brothers have wisdom and make the bes...</td>\n",
       "      <td>142</td>\n",
       "      <td>['#eleccionesargentina']</td>\n",
       "      <td>eleccionesargentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mob-device</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sentiment(polarity=1.0, subjectivity=0.3)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11584</td>\n",
       "      <td>11584</td>\n",
       "      <td>2019-10-27 19:06:10+00:00</td>\n",
       "      <td>1552580563</td>\n",
       "      <td>aydaralfredo</td>\n",
       "      <td>ché @fantinofantino te acordas cuando le grita...</td>\n",
       "      <td>che te acordas cuando le gritabas apara turco ...</td>\n",
       "      <td>What do you remember when you yelled Turkish a...</td>\n",
       "      <td>234</td>\n",
       "      <td>['#albertopresidente', '#periodismobasura', '#...</td>\n",
       "      <td>albertopresidente,periodismobasura,elecciones2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>android</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sentiment(polarity=0.5, subjectivity=0.5)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11585</td>\n",
       "      <td>11585</td>\n",
       "      <td>2019-10-27 19:06:10+00:00</td>\n",
       "      <td>239100413</td>\n",
       "      <td>rafaelperafan</td>\n",
       "      <td>en el municipio de #topaipi en      #cundinama...</td>\n",
       "      <td>en el municipio de enpartidarios del candidato...</td>\n",
       "      <td>in the municipality of enpartidarios of the ca...</td>\n",
       "      <td>250</td>\n",
       "      <td>['#topaipi', '#cundinamarca', '#elecciones2019']</td>\n",
       "      <td>topaipi,cundinamarca,elecciones2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>android</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sentiment(polarity=0.2, subjectivity=0.3)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11586</td>\n",
       "      <td>11586</td>\n",
       "      <td>2019-10-27 19:06:11+00:00</td>\n",
       "      <td>1302834792</td>\n",
       "      <td>aleph52v</td>\n",
       "      <td>#cepo #volvimos primeras imágenes en el búnker...</td>\n",
       "      <td>primeras imagenes en el bunker de macri despue...</td>\n",
       "      <td>first images in the macri bunker after announc...</td>\n",
       "      <td>157</td>\n",
       "      <td>['#cepo', '#volvimos', '#eleccionesargentina']</td>\n",
       "      <td>cepo,volvimos,eleccionesargentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>android</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sentiment(polarity=0.25, subjectivity=0.333333...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11587</td>\n",
       "      <td>11587</td>\n",
       "      <td>2019-10-27 19:06:12+00:00</td>\n",
       "      <td>2728707039</td>\n",
       "      <td>laligrumelli</td>\n",
       "      <td>horas antes de que salgan los resultados ya ha...</td>\n",
       "      <td>horas antes de que salgan los resultados ya ha...</td>\n",
       "      <td>hours before the results come out there was al...</td>\n",
       "      <td>225</td>\n",
       "      <td>['#eleccionesenpublicable']</td>\n",
       "      <td>eleccionesenpublicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>android</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sentiment(polarity=0.20000000000000004, subjec...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11588</td>\n",
       "      <td>11588</td>\n",
       "      <td>2019-10-27 19:06:12+00:00</td>\n",
       "      <td>1175418454850994176</td>\n",
       "      <td>nafisa14453347</td>\n",
       "      <td>https://t.co/lcjxyconoa\\nthe grimeyboys tv sho...</td>\n",
       "      <td>the grimeyboys tv show\\namazing show</td>\n",
       "      <td>the grimeyboys tv show amazing show</td>\n",
       "      <td>280</td>\n",
       "      <td>['#crackerswalidiwali', '#eleccionesargentina'...</td>\n",
       "      <td>crackerswalidiwali,eleccionesargentina,ehdewaf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>android</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sentiment(polarity=0.6000000000000001, subject...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11589 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                  timestamp                   id  \\\n",
       "0               0  2019-10-27 12:53:55+00:00  1162811195671416833   \n",
       "1               1  2019-10-27 12:53:56+00:00            404900481   \n",
       "2               2  2019-10-27 12:53:59+00:00  1165778412637736963   \n",
       "3               3  2019-10-27 12:53:59+00:00            391643721   \n",
       "4               4  2019-10-27 12:54:03+00:00  1153794949336444928   \n",
       "...           ...                        ...                  ...   \n",
       "11584       11584  2019-10-27 19:06:10+00:00           1552580563   \n",
       "11585       11585  2019-10-27 19:06:10+00:00            239100413   \n",
       "11586       11586  2019-10-27 19:06:11+00:00           1302834792   \n",
       "11587       11587  2019-10-27 19:06:12+00:00           2728707039   \n",
       "11588       11588  2019-10-27 19:06:12+00:00  1175418454850994176   \n",
       "\n",
       "             username                                          text_orig  \\\n",
       "0          annyroshi_  #felizdomingo! hoy es un día especial y vale l...   \n",
       "1           gonza_v12  todas las boletas de macri rotas. escuela 57 d...   \n",
       "2             comunon  mas denuncias\\nmas escuelas clausuradas\\nmenos...   \n",
       "3         marchaorgar  #eleccionesargentina\\n\\nmientras nos preparamo...   \n",
       "4         xisdavidaii  que nuestros hermanos tengan sabiduría y hagan...   \n",
       "...               ...                                                ...   \n",
       "11584    aydaralfredo  ché @fantinofantino te acordas cuando le grita...   \n",
       "11585   rafaelperafan  en el municipio de #topaipi en      #cundinama...   \n",
       "11586        aleph52v  #cepo #volvimos primeras imágenes en el búnker...   \n",
       "11587    laligrumelli  horas antes de que salgan los resultados ya ha...   \n",
       "11588  nafisa14453347  https://t.co/lcjxyconoa\\nthe grimeyboys tv sho...   \n",
       "\n",
       "                                              text_modif  \\\n",
       "0      hoy es un dia especial y vale la pena correrme...   \n",
       "1      todas las boletas de macri rotas escuela 57 de...   \n",
       "2      mas denuncias\\nmas escuelas clausuradas\\nmenos...   \n",
       "3      mientras nos preparamos para el festejo nos an...   \n",
       "4      que nuestros hermanos tengan sabiduria y hagan...   \n",
       "...                                                  ...   \n",
       "11584  che te acordas cuando le gritabas apara turco ...   \n",
       "11585  en el municipio de enpartidarios del candidato...   \n",
       "11586  primeras imagenes en el bunker de macri despue...   \n",
       "11587  horas antes de que salgan los resultados ya ha...   \n",
       "11588               the grimeyboys tv show\\namazing show   \n",
       "\n",
       "                                                 text_en  lenght  \\\n",
       "0      Today is a special day and it is worth taking ...     252   \n",
       "1      all the macri school 57 broken tickets of el p...     111   \n",
       "2      more complaints more schools closed less kirch...     277   \n",
       "3      As we prepare for the celebration, we encourag...     211   \n",
       "4      that our brothers have wisdom and make the bes...     142   \n",
       "...                                                  ...     ...   \n",
       "11584  What do you remember when you yelled Turkish a...     234   \n",
       "11585  in the municipality of enpartidarios of the ca...     250   \n",
       "11586  first images in the macri bunker after announc...     157   \n",
       "11587  hours before the results come out there was al...     225   \n",
       "11588                the grimeyboys tv show amazing show     280   \n",
       "\n",
       "                                           hashtags_orig  \\\n",
       "0             ['#felizdomingo!', '#eleccionesargentina']   \n",
       "1                               ['#eleccionesargentina']   \n",
       "2      ['#seamoslibreslodemassearregla', '#sisepuede'...   \n",
       "3                 ['#eleccionesargentina', '#argentina']   \n",
       "4                               ['#eleccionesargentina']   \n",
       "...                                                  ...   \n",
       "11584  ['#albertopresidente', '#periodismobasura', '#...   \n",
       "11585   ['#topaipi', '#cundinamarca', '#elecciones2019']   \n",
       "11586     ['#cepo', '#volvimos', '#eleccionesargentina']   \n",
       "11587                        ['#eleccionesenpublicable']   \n",
       "11588  ['#crackerswalidiwali', '#eleccionesargentina'...   \n",
       "\n",
       "                                          hashtags_modif  location  \\\n",
       "0                      felizdomingo!,eleccionesargentina       NaN   \n",
       "1                                    eleccionesargentina       NaN   \n",
       "2      seamoslibreslodemassearregla,sisepuede,maurici...       NaN   \n",
       "3                          eleccionesargentina,argentina       NaN   \n",
       "4                                    eleccionesargentina       NaN   \n",
       "...                                                  ...       ...   \n",
       "11584  albertopresidente,periodismobasura,elecciones2019       NaN   \n",
       "11585                topaipi,cundinamarca,elecciones2019       NaN   \n",
       "11586                  cepo,volvimos,eleccionesargentina       NaN   \n",
       "11587                             eleccionesenpublicable       NaN   \n",
       "11588  crackerswalidiwali,eleccionesargentina,ehdewaf...       NaN   \n",
       "\n",
       "           device  verified     rt reply  \\\n",
       "0         android     False  False   NaN   \n",
       "1          iphone     False  False   NaN   \n",
       "2         android     False  False   NaN   \n",
       "3         android     False  False   NaN   \n",
       "4      mob-device     False  False   NaN   \n",
       "...           ...       ...    ...   ...   \n",
       "11584     android     False  False   NaN   \n",
       "11585     android     False  False   NaN   \n",
       "11586     android     False  False   NaN   \n",
       "11587     android     False  False   NaN   \n",
       "11588     android     False  False   NaN   \n",
       "\n",
       "                                          sentiment_orig  sent      subj  \n",
       "0      Sentiment(polarity=0.23435374149659863, subjec...   1.0  0.255442  \n",
       "1             Sentiment(polarity=-0.4, subjectivity=0.4)   0.0  0.400000  \n",
       "2      Sentiment(polarity=0.18333333333333335, subjec...   1.0  0.291667  \n",
       "3          Sentiment(polarity=0.20625, subjectivity=0.7)   1.0  0.700000  \n",
       "4              Sentiment(polarity=1.0, subjectivity=0.3)   1.0  0.300000  \n",
       "...                                                  ...   ...       ...  \n",
       "11584          Sentiment(polarity=0.5, subjectivity=0.5)   1.0  0.500000  \n",
       "11585          Sentiment(polarity=0.2, subjectivity=0.3)   1.0  0.300000  \n",
       "11586  Sentiment(polarity=0.25, subjectivity=0.333333...   1.0  0.333333  \n",
       "11587  Sentiment(polarity=0.20000000000000004, subjec...   1.0  0.650000  \n",
       "11588  Sentiment(polarity=0.6000000000000001, subject...   1.0  0.900000  \n",
       "\n",
       "[11589 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#Importamos las StopWord para español\n",
    "stopwords = nltk.corpus.stopwords.words('spanish')\n",
    "\n",
    "#Agregamos algunas stopword mas que aportaban solo ruido\n",
    "newStopWords = ['mas','bettina', 'romero', 'aos', 'tambien', 'chavistas', 'looken']\n",
    "stopwords.extend(newStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizamos el split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tw['text_modif'], tw['sent'],random_state=42, stratify=tw['sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect= TfidfVectorizer(stop_words=None,min_df=5,ngram_range=(1, 7))\n",
    "X_train=vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8691x11200 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 216836 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-209-2d8a0cfaca31>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-209-2d8a0cfaca31>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    ('model', model)\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "pipe_master = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('model', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3317     1.0\n",
       "4554     1.0\n",
       "6489     1.0\n",
       "8683     0.0\n",
       "2275     1.0\n",
       "        ... \n",
       "9962     1.0\n",
       "147      1.0\n",
       "10338    1.0\n",
       "3456     0.0\n",
       "10380    1.0\n",
       "Name: sent, Length: 8691, dtype: float64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def batch_generator(X_data, y_data, batch_size):\n",
    "    samples_per_epoch = X_data.shape[0]\n",
    "    number_of_batches = samples_per_epoch/batch_size\n",
    "    counter=0\n",
    "    index = np.arange(np.shape(y_data)[0])\n",
    "    while 1:\n",
    "        index_batch = index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X_data[index_batch,:].toarray()\n",
    "        y_batch = y_data[y_data.index[index_batch]]\n",
    "        counter += 1\n",
    "        yield X_batch,y_batch\n",
    "        if (counter > number_of_batches):\n",
    "            counter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11200"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X_train.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "272/271 [==============================] - 4s 14ms/step - loss: 0.6641 - acc: 0.6435\n",
      "Epoch 2/10\n",
      "272/271 [==============================] - 3s 9ms/step - loss: 0.6157 - acc: 0.7087\n",
      "Epoch 3/10\n",
      "272/271 [==============================] - 3s 10ms/step - loss: 0.6076 - acc: 0.7136\n",
      "Epoch 4/10\n",
      "272/271 [==============================] - 3s 10ms/step - loss: 0.5958 - acc: 0.7146\n",
      "Epoch 5/10\n",
      "272/271 [==============================] - 3s 9ms/step - loss: 0.5307 - acc: 0.7378\n",
      "Epoch 6/10\n",
      "272/271 [==============================] - 3s 9ms/step - loss: 0.3604 - acc: 0.8529\n",
      "Epoch 7/10\n",
      "272/271 [==============================] - 3s 10ms/step - loss: 0.2643 - acc: 0.9024\n",
      "Epoch 8/10\n",
      "272/271 [==============================] - 3s 9ms/step - loss: 0.2023 - acc: 0.9300\n",
      "Epoch 9/10\n",
      "272/271 [==============================] - 3s 10ms/step - loss: 0.1625 - acc: 0.9513\n",
      "Epoch 10/10\n",
      "272/271 [==============================] - 3s 9ms/step - loss: 0.1314 - acc: 0.9630\n",
      "Wall time: 27.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x57e2a550>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dim=X_train.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='sigmoid', input_dim=dim)),\n",
    "model.add(Dense(32, activation='sigmoid')),\n",
    "model.add(Dense(16, activation='sigmoid')),\n",
    "model.add(Dropout(0.5)),\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(generator=batch_generator(X_train, y_train, 32),\n",
    "                    epochs=10,\n",
    "                    steps_per_epoch=X_train.shape[0]/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_master = Pipeline([\n",
    "    ('vect', TfidfVectorizer())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds=model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9920299 ],\n",
       "       [0.99622965],\n",
       "       [0.9887533 ],\n",
       "       ...,\n",
       "       [0.99561465],\n",
       "       [0.0158515 ],\n",
       "       [0.9959096 ]], dtype=float32)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_int=y_preds.round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.97      0.97      2481\n",
      "         1.0       0.99      0.98      0.99      6210\n",
      "\n",
      "    accuracy                           0.98      8691\n",
      "   macro avg       0.97      0.98      0.98      8691\n",
      "weighted avg       0.98      0.98      0.98      8691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_preds_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_test=model.predict(X_test).round(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.69      0.69       827\n",
      "         1.0       0.88      0.87      0.87      2071\n",
      "\n",
      "    accuracy                           0.82      2898\n",
      "   macro avg       0.78      0.78      0.78      2898\n",
      "weighted avg       0.82      0.82      0.82      2898\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(vect.transform(['Celebramos la democracia una vez más! Se siente, se siente Alberto Presidente'])).round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(vect.transform(['No pudieron. Ni trayendo matones de La Matanza , ni tirando clavos miguelito, ni robando boletas. Simplemente Dolores les que dijo que NO!! '])).round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(vect.transform(['Iban a volver mejores, y terminaron anunciando que van a eliminar el decreto que declara a Hezbollah como organización terrorista. Se están pasando a los muertos de la AMIA por el orto y ustedes lo votaron, pelotudos.'])).round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(vect.transform(['Buen Domingo Para Todes! Yo estoy camino al colegio a Votar y después a trabajar! Le dejo el Pronóstico!'])).round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(vect.transform(['Por Néstor, por nuestra querida Patria. Para que vuelvan los días felices. VAMOS  Alberto, desde cada rincón estamos con vos.'])).round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.predict(vect.transform(['que pobre el periodismo! ya ni siquiera me da bronca lo que dan es pena'])).round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 570,  257],\n",
       "       [ 262, 1809]], dtype=int64)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Train\n",
      "0.9938501695007663\n",
      "-------------------\n",
      "AUC Test\n",
      "0.7813646387581836\n"
     ]
    }
   ],
   "source": [
    "print('AUC Train')\n",
    "print(roc_auc_score(y_train,y_preds))\n",
    "print('-------------------')\n",
    "print('AUC Test')\n",
    "print(roc_auc_score(y_test,y_preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
